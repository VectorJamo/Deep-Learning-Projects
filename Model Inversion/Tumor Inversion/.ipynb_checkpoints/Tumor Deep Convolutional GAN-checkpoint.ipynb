{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3a6720-f4d4-487b-b9b4-b4c5b0dff652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Deep Convolutional Generative Adverserial Network that creates realistic Tumor images\n",
    "# Author: Suraj Neupane\n",
    "# Written from scratch as a part of a Research Project 2025, Concordia University of Edmonton.\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39fb5668-79ac-461c-93fb-601c6828aae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu118'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba3a436-a29d-4c49-a3da-43cc447768dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9beae6ba-c5e2-40c3-b2bc-bf8fef7508c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the images to 64x64\n",
    "#transformations = transforms.Compose(\n",
    "    #[\n",
    "        #transforms.Resize(img_size),\n",
    "        #transforms.ToTensor(),\n",
    "        #transforms.Normalize(\n",
    "            #[0.5 for _ in range(img_channels)], [0.5 for _ in range(img_channels)]\n",
    "        #)\n",
    "    #]\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd749c06-aff5-48e2-a62c-e0ddbfdb77b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                            # SECTION 1: Dataset Loading\n",
    "# Load the .pkl files in as numpy arrays of pixels\n",
    "def load_tumor_data(file_path):\n",
    "    train_xs = []\n",
    "    train_ys = []\n",
    "    \"\"\" Load Digits Data from pickle data\n",
    "    return:\n",
    "    @xs: numpy.array, (n, c, w, h) \n",
    "    @ys: numpy.array, (n, ), 0-9\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "        train_xs.append(data[\"data\"])\n",
    "        train_ys.append(data[\"labels\"])\n",
    "    train_xs = np.concatenate(train_xs, axis=0)\n",
    "    train_ys = np.concatenate(train_ys, axis=0)\n",
    "    \n",
    "    return train_xs, train_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ae14f23-7705-4620-87f7-c76d41ed341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Tumor Dataset\n",
    "class TumorDataset(data.Dataset):\n",
    "    def __init__(self, xs, ys, is_train=True):\n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "\n",
    "        if is_train is True:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((64, 64)),\n",
    "                transforms.ToTensor(),\n",
    "                #transforms.Normalize(\n",
    "                    #(0.4914, 0.4822, 0.4465),\n",
    "                    #(0.2023, 0.1994, 0.2010)\n",
    "                #)\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((64, 64)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    (0.4914, 0.4822, 0.4465),\n",
    "                    (0.2023, 0.1994, 0.2010)\n",
    "                )\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.xs[index]\n",
    "        #print(img.shape)\n",
    "        label = self.ys[index]\n",
    "\n",
    "        img = img.transpose((1, 2, 0)).astype(np.uint8)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        img = torch.FloatTensor(img)\n",
    "        label = torch.LongTensor([label])[0]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a41a16a-edac-4a89-9c12-65f4c17bc2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(train_xs, train_ys):\n",
    "    tumor_dataset = TumorDataset(train_xs, train_ys, is_train=True)\n",
    "\n",
    "    return tumor_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9735b1ae-0cbd-4225-b682-e0f184905379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset):\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5001ea3-a1de-44fb-a246-3a11af3c1aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13927, 1, 32, 32)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Load in the pickle dataset file\n",
    "train_xs, train_ys = load_tumor_data('datasets/Tumor/tumor4train.pkl')\n",
    "#train_xs = train_xs[:, 1, :, :]\n",
    "#train_xs = np.expand_dims(train_xs, axis=1)\n",
    "train_xs_modified = train_xs.mean(axis=1, keepdims=True)\n",
    "print(train_xs_modified.shape)\n",
    "print(type(train_xs_modified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6411a28b-5997-4c7b-aec7-6f5a0ce414b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "tumor_dataset = create_dataset(train_xs, train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed5ff6be-4bd7-41a8-83e1-326abbbbdb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(image_x):\n",
    "    # We have to visualize by reverting the normalization (just for visualization).\n",
    "    #mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "    #std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "\n",
    "    #image = image_x * std + mean  # Denormalize the image\n",
    "\n",
    "    #image = torch.clamp(image, 0, 1) # Clip values to [0, 1] to ensure valid range for display\n",
    "\n",
    "    # Permute the image to (H, W, C) for matplotlib\n",
    "    \n",
    "    image = image_x.permute(1, 2, 0)\n",
    "\n",
    "    plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1c6efd2-b413-4104-9f0e-7a34634c7229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the first tumor sample. \n",
    "image_x, image_y = tumor_dataset[13339]\n",
    "print(image_x.shape)\n",
    "visualize_image(image_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888b4342-860b-4337-b9fc-d647bd34e7d2",
   "metadata": {},
   "source": [
    "# Create the dataloader\n",
    "tumor_dataloader = create_dataloader(tumor_dataset)\n",
    "\n",
    "tumor_iter = iter(tumor_dataloader)\n",
    "batch1_xs, batch1_ys = next(tumor_iter)\n",
    "visualize_image(batch1_xs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "979c5c00-402c-4cc2-a54b-09807366602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the DC-GAN\n",
    "# Creating the Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels, features_d):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # Input shape: img_channels x 64 x 64\n",
    "            nn.Conv2d(\n",
    "              in_channels=img_channels, out_channels=features_d, kernel_size=4, stride=2, padding=1\n",
    "            ), # Output shape: features_d x 32 x 32\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d, features_d*2, 4, 2, 1), # Output shape: features_d*2 x 16 x 16\n",
    "            self._block(features_d*2, features_d*4, 4, 2, 1), # Output shape: features_d*4 x 8 x 8\n",
    "            self._block(features_d*4, features_d*8, 4, 2, 1), # Output shape: features_d*8 x 4 x 4\n",
    "           \n",
    "            nn.Conv2d(in_channels=features_d*8, out_channels=1, kernel_size=4, stride=2, padding=0), # Output shape: 1 x 1\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.disc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d74e527-2960-456a-a09a-bda128387337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_channels, features_g):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            self._block(z_dim, features_g*16, 4, 1, 0), # z_dim: (batch_size, 100, 1, 1) -> (batch_size, 1024, 4, 4)\n",
    "            self._block(features_g*16, features_g*8, 4, 2, 1), # z_dim: (batch_size, 1024, 4, 4) -> (batch_size, 512, 8, 8)\n",
    "            self._block(features_g*8, features_g*4, 4, 2, 1), # z_dim: (batch_size, 512, 8, 8) -> (batch_size, 256, 16, 16)\n",
    "            self._block(features_g*4, features_g*2, 4, 2, 1), # z_dim: (batch_size, 128, 16, 16) -> (batch_size, 64, 32, 32)\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=features_g*2, out_channels=img_channels, kernel_size=4, stride=2, padding=1 # z_dim: (batch_size, 64, 32, 32) -> (batch_size, 1, 64, 64)\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.gen(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19e70627-f849-49a5-a720-3b528ea4ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b8e5466-2f2d-4cdd-9a1d-b2035bf0c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the output shapes of the Discriminator and the Generator\n",
    "def test():\n",
    "    N, in_channels, H, W = 8, 3, 64, 64\n",
    "    z_dim = 100\n",
    "    x = torch.randn((N, in_channels, H, W))\n",
    "    disc = Discriminator(in_channels, 8)\n",
    "    initialize_weights(disc)\n",
    "\n",
    "    print(disc(x).shape)\n",
    "    assert disc(x).shape == (N, 1, 1, 1)\n",
    "\n",
    "    gen = Generator(z_dim, in_channels, 8)\n",
    "    initialize_weights(gen)\n",
    "    z = torch.randn((N, z_dim, 1, 1))\n",
    "\n",
    "    print(gen(z).shape)\n",
    "    assert(gen(z).shape) == (N, in_channels, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "796beb13-12fb-49e8-a4b4-b172798dbb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 1, 1])\n",
      "torch.Size([8, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a403cf18-b222-4b8d-8e63-63da7286b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the hyperparameters\n",
    "learning_rate = 2e-4\n",
    "batch_size = 128\n",
    "image_size = 64\n",
    "img_channels = 1\n",
    "z_dim = 100\n",
    "epochs = 80\n",
    "features_disc = 64\n",
    "features_gen = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e29c242b-0645-426f-9b73-f94df06f510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model instances\n",
    "gen = Generator(z_dim, img_channels, features_gen).to(device)\n",
    "disc = Discriminator(img_channels, features_disc).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b89e4cba-fa56-4686-adf0-f648351ff389",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_weights(gen)\n",
    "initialize_weights(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61b63f9d-e4af-4604-b3bc-cc338ae38fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer and the loss function\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fbc5de3-c51c-4378-b922-19596f757098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (disc): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (6): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the models to training mode\n",
    "gen.train()\n",
    "disc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d2b1f68-953b-4e64-a681-2a95f6b71a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Batches seen: 0.\n",
      "Loss D: 0.6962646842002869, Loss G: 0.7631782293319702\n",
      "Epoch: 0. Batches seen: 50.\n",
      "Loss D: 0.6077139377593994, Loss G: 0.7874537706375122\n",
      "Epoch: 0. Batches seen: 100.\n",
      "Loss D: 0.7414425611495972, Loss G: 0.6997830867767334\n",
      "Epoch: 1. Batches seen: 0.\n",
      "Loss D: 0.5066588521003723, Loss G: 1.3210325241088867\n",
      "Epoch: 1. Batches seen: 50.\n",
      "Loss D: 0.5915143489837646, Loss G: 1.2073620557785034\n",
      "Epoch: 1. Batches seen: 100.\n",
      "Loss D: 0.3726837635040283, Loss G: 1.637984037399292\n",
      "Epoch: 2. Batches seen: 0.\n",
      "Loss D: 0.5843597650527954, Loss G: 1.3794257640838623\n",
      "Epoch: 2. Batches seen: 50.\n",
      "Loss D: 0.8409956693649292, Loss G: 0.922921895980835\n",
      "Epoch: 2. Batches seen: 100.\n",
      "Loss D: 0.6825677156448364, Loss G: 1.2354865074157715\n",
      "Epoch: 3. Batches seen: 0.\n",
      "Loss D: 0.5076264142990112, Loss G: 1.2935926914215088\n",
      "Epoch: 3. Batches seen: 50.\n",
      "Loss D: 0.6423035860061646, Loss G: 1.0442489385604858\n",
      "Epoch: 3. Batches seen: 100.\n",
      "Loss D: 0.5278286337852478, Loss G: 1.2355096340179443\n",
      "Epoch: 4. Batches seen: 0.\n",
      "Loss D: 0.5348271727561951, Loss G: 1.1035428047180176\n",
      "Epoch: 4. Batches seen: 50.\n",
      "Loss D: 0.6568645238876343, Loss G: 1.1179438829421997\n",
      "Epoch: 4. Batches seen: 100.\n",
      "Loss D: 0.5007503032684326, Loss G: 1.752959966659546\n",
      "Epoch: 5. Batches seen: 0.\n",
      "Loss D: 0.5097732543945312, Loss G: 1.200589895248413\n",
      "Epoch: 5. Batches seen: 50.\n",
      "Loss D: 0.6453452706336975, Loss G: 1.0074772834777832\n",
      "Epoch: 5. Batches seen: 100.\n",
      "Loss D: 0.6030242443084717, Loss G: 0.890308141708374\n",
      "Epoch: 6. Batches seen: 0.\n",
      "Loss D: 0.4233905076980591, Loss G: 1.4950268268585205\n",
      "Epoch: 6. Batches seen: 50.\n",
      "Loss D: 0.45839253067970276, Loss G: 1.4845857620239258\n",
      "Epoch: 6. Batches seen: 100.\n",
      "Loss D: 0.36535683274269104, Loss G: 1.541696548461914\n",
      "Epoch: 7. Batches seen: 0.\n",
      "Loss D: 0.5891925096511841, Loss G: 1.9082140922546387\n",
      "Epoch: 7. Batches seen: 50.\n",
      "Loss D: 0.35016751289367676, Loss G: 1.4898724555969238\n",
      "Epoch: 7. Batches seen: 100.\n",
      "Loss D: 0.4985463321208954, Loss G: 1.299234390258789\n",
      "Epoch: 8. Batches seen: 0.\n",
      "Loss D: 0.5428745150566101, Loss G: 0.7142572999000549\n",
      "Epoch: 8. Batches seen: 50.\n",
      "Loss D: 0.7808477282524109, Loss G: 1.3216605186462402\n",
      "Epoch: 8. Batches seen: 100.\n",
      "Loss D: 0.5364124774932861, Loss G: 1.3305890560150146\n",
      "Epoch: 9. Batches seen: 0.\n",
      "Loss D: 0.6163793802261353, Loss G: 1.377763032913208\n",
      "Epoch: 9. Batches seen: 50.\n",
      "Loss D: 0.544043779373169, Loss G: 0.9015969038009644\n",
      "Epoch: 9. Batches seen: 100.\n",
      "Loss D: 0.290720134973526, Loss G: 1.6954572200775146\n",
      "Epoch: 10. Batches seen: 0.\n",
      "Loss D: 0.27592065930366516, Loss G: 1.7965741157531738\n",
      "Epoch: 10. Batches seen: 50.\n",
      "Loss D: 0.3857104182243347, Loss G: 1.4719088077545166\n",
      "Epoch: 10. Batches seen: 100.\n",
      "Loss D: 0.3407217860221863, Loss G: 1.4244986772537231\n",
      "Epoch: 11. Batches seen: 0.\n",
      "Loss D: 0.7805870771408081, Loss G: 0.9303609132766724\n",
      "Epoch: 11. Batches seen: 50.\n",
      "Loss D: 0.39431238174438477, Loss G: 1.4551987648010254\n",
      "Epoch: 11. Batches seen: 100.\n",
      "Loss D: 0.47406527400016785, Loss G: 1.0586663484573364\n",
      "Epoch: 12. Batches seen: 0.\n",
      "Loss D: 0.23166200518608093, Loss G: 1.80427885055542\n",
      "Epoch: 12. Batches seen: 50.\n",
      "Loss D: 0.37200045585632324, Loss G: 1.4821211099624634\n",
      "Epoch: 12. Batches seen: 100.\n",
      "Loss D: 0.3573151230812073, Loss G: 2.116143226623535\n",
      "Epoch: 13. Batches seen: 0.\n",
      "Loss D: 0.7041165828704834, Loss G: 1.2540819644927979\n",
      "Epoch: 13. Batches seen: 50.\n",
      "Loss D: 0.3389539420604706, Loss G: 1.6646937131881714\n",
      "Epoch: 13. Batches seen: 100.\n",
      "Loss D: 0.28810322284698486, Loss G: 1.3515923023223877\n",
      "Epoch: 14. Batches seen: 0.\n",
      "Loss D: 0.5372552871704102, Loss G: 1.904923915863037\n",
      "Epoch: 14. Batches seen: 50.\n",
      "Loss D: 0.4031495451927185, Loss G: 2.0554070472717285\n",
      "Epoch: 14. Batches seen: 100.\n",
      "Loss D: 0.2619566023349762, Loss G: 1.8481769561767578\n",
      "Epoch: 15. Batches seen: 0.\n",
      "Loss D: 0.22217348217964172, Loss G: 1.330925464630127\n",
      "Epoch: 15. Batches seen: 50.\n",
      "Loss D: 0.10086623579263687, Loss G: 2.5611732006073\n",
      "Epoch: 15. Batches seen: 100.\n",
      "Loss D: 0.12226930260658264, Loss G: 3.2598071098327637\n",
      "Epoch: 16. Batches seen: 0.\n",
      "Loss D: 0.6263353824615479, Loss G: 1.1512477397918701\n",
      "Epoch: 16. Batches seen: 50.\n",
      "Loss D: 0.2503074109554291, Loss G: 2.172978639602661\n",
      "Epoch: 16. Batches seen: 100.\n",
      "Loss D: 0.3312738537788391, Loss G: 1.7831439971923828\n",
      "Epoch: 17. Batches seen: 0.\n",
      "Loss D: 0.2702266573905945, Loss G: 1.8117913007736206\n",
      "Epoch: 17. Batches seen: 50.\n",
      "Loss D: 0.7398483753204346, Loss G: 1.375707983970642\n",
      "Epoch: 17. Batches seen: 100.\n",
      "Loss D: 0.5490224957466125, Loss G: 1.4522377252578735\n",
      "Epoch: 18. Batches seen: 0.\n",
      "Loss D: 0.19741585850715637, Loss G: 2.2381207942962646\n",
      "Epoch: 18. Batches seen: 50.\n",
      "Loss D: 0.5405781269073486, Loss G: 1.0047105550765991\n",
      "Epoch: 18. Batches seen: 100.\n",
      "Loss D: 0.40745341777801514, Loss G: 1.3025256395339966\n",
      "Epoch: 19. Batches seen: 0.\n",
      "Loss D: 0.8655787110328674, Loss G: 1.723107933998108\n",
      "Epoch: 19. Batches seen: 50.\n",
      "Loss D: 0.7301879525184631, Loss G: 1.8370912075042725\n",
      "Epoch: 19. Batches seen: 100.\n",
      "Loss D: 0.5277604460716248, Loss G: 1.4774038791656494\n",
      "Epoch: 20. Batches seen: 0.\n",
      "Loss D: 0.3465209901332855, Loss G: 1.3087546825408936\n",
      "Epoch: 20. Batches seen: 50.\n",
      "Loss D: 0.4832831025123596, Loss G: 1.8030755519866943\n",
      "Epoch: 20. Batches seen: 100.\n",
      "Loss D: 0.3875148892402649, Loss G: 1.278291940689087\n",
      "Epoch: 21. Batches seen: 0.\n",
      "Loss D: 0.29371172189712524, Loss G: 1.8970248699188232\n",
      "Epoch: 21. Batches seen: 50.\n",
      "Loss D: 0.248261496424675, Loss G: 1.4122793674468994\n",
      "Epoch: 21. Batches seen: 100.\n",
      "Loss D: 0.3059476912021637, Loss G: 1.3366234302520752\n",
      "Epoch: 22. Batches seen: 0.\n",
      "Loss D: 0.3520860970020294, Loss G: 1.5710539817810059\n",
      "Epoch: 22. Batches seen: 50.\n",
      "Loss D: 0.5981049537658691, Loss G: 1.4806292057037354\n",
      "Epoch: 22. Batches seen: 100.\n",
      "Loss D: 0.15219426155090332, Loss G: 2.881077766418457\n",
      "Epoch: 23. Batches seen: 0.\n",
      "Loss D: 0.17924396693706512, Loss G: 1.801544189453125\n",
      "Epoch: 23. Batches seen: 50.\n",
      "Loss D: 0.5835697650909424, Loss G: 1.3617408275604248\n",
      "Epoch: 23. Batches seen: 100.\n",
      "Loss D: 0.3282287120819092, Loss G: 1.0988880395889282\n",
      "Epoch: 24. Batches seen: 0.\n",
      "Loss D: 0.20524094998836517, Loss G: 2.304326057434082\n",
      "Epoch: 24. Batches seen: 50.\n",
      "Loss D: 0.07546079903841019, Loss G: 2.824777126312256\n",
      "Epoch: 24. Batches seen: 100.\n",
      "Loss D: 0.12700925767421722, Loss G: 2.8249881267547607\n",
      "Epoch: 25. Batches seen: 0.\n",
      "Loss D: 0.6100736260414124, Loss G: 1.3729405403137207\n",
      "Epoch: 25. Batches seen: 50.\n",
      "Loss D: 0.23298095166683197, Loss G: 1.6858108043670654\n",
      "Epoch: 25. Batches seen: 100.\n",
      "Loss D: 0.19825899600982666, Loss G: 1.9701452255249023\n",
      "Epoch: 26. Batches seen: 0.\n",
      "Loss D: 0.21799197793006897, Loss G: 2.01804780960083\n",
      "Epoch: 26. Batches seen: 50.\n",
      "Loss D: 0.3883166015148163, Loss G: 1.4044666290283203\n",
      "Epoch: 26. Batches seen: 100.\n",
      "Loss D: 0.2899373769760132, Loss G: 1.7886414527893066\n",
      "Epoch: 27. Batches seen: 0.\n",
      "Loss D: 0.2769375443458557, Loss G: 1.988526463508606\n",
      "Epoch: 27. Batches seen: 50.\n",
      "Loss D: 0.5633473992347717, Loss G: 1.5773754119873047\n",
      "Epoch: 27. Batches seen: 100.\n",
      "Loss D: 0.17472770810127258, Loss G: 1.6982663869857788\n",
      "Epoch: 28. Batches seen: 0.\n",
      "Loss D: 0.28903505206108093, Loss G: 1.9496192932128906\n",
      "Epoch: 28. Batches seen: 50.\n",
      "Loss D: 0.2023778259754181, Loss G: 2.1708898544311523\n",
      "Epoch: 28. Batches seen: 100.\n",
      "Loss D: 0.09632301330566406, Loss G: 2.7158286571502686\n",
      "Epoch: 29. Batches seen: 0.\n",
      "Loss D: 0.5576335191726685, Loss G: 1.5666714906692505\n",
      "Epoch: 29. Batches seen: 50.\n",
      "Loss D: 0.16541963815689087, Loss G: 2.2420856952667236\n",
      "Epoch: 29. Batches seen: 100.\n",
      "Loss D: 0.21316106617450714, Loss G: 1.8338792324066162\n",
      "Epoch: 30. Batches seen: 0.\n",
      "Loss D: 0.3738807439804077, Loss G: 1.3307280540466309\n",
      "Epoch: 30. Batches seen: 50.\n",
      "Loss D: 0.26467177271842957, Loss G: 1.437103509902954\n",
      "Epoch: 30. Batches seen: 100.\n",
      "Loss D: 0.22269068658351898, Loss G: 2.4270524978637695\n",
      "Epoch: 31. Batches seen: 0.\n",
      "Loss D: 0.29764512181282043, Loss G: 3.4284539222717285\n",
      "Epoch: 31. Batches seen: 50.\n",
      "Loss D: 0.20790863037109375, Loss G: 2.149601459503174\n",
      "Epoch: 31. Batches seen: 100.\n",
      "Loss D: 0.2727288603782654, Loss G: 1.7189416885375977\n",
      "Epoch: 32. Batches seen: 0.\n",
      "Loss D: 0.1577713042497635, Loss G: 2.2674055099487305\n",
      "Epoch: 32. Batches seen: 50.\n",
      "Loss D: 0.060065045952796936, Loss G: 3.243610382080078\n",
      "Epoch: 32. Batches seen: 100.\n",
      "Loss D: 0.37714695930480957, Loss G: 1.2320797443389893\n",
      "Epoch: 33. Batches seen: 0.\n",
      "Loss D: 0.30117958784103394, Loss G: 2.146167039871216\n",
      "Epoch: 33. Batches seen: 50.\n",
      "Loss D: 0.5077246427536011, Loss G: 1.6637401580810547\n",
      "Epoch: 33. Batches seen: 100.\n",
      "Loss D: 0.24399374425411224, Loss G: 1.841705560684204\n",
      "Epoch: 34. Batches seen: 0.\n",
      "Loss D: 0.4484340250492096, Loss G: 2.668456554412842\n",
      "Epoch: 34. Batches seen: 50.\n",
      "Loss D: 0.009340999647974968, Loss G: 5.364662170410156\n",
      "Epoch: 34. Batches seen: 100.\n",
      "Loss D: 0.044257719069719315, Loss G: 3.423964500427246\n",
      "Epoch: 35. Batches seen: 0.\n",
      "Loss D: 0.08509175479412079, Loss G: 2.590547800064087\n",
      "Epoch: 35. Batches seen: 50.\n",
      "Loss D: 0.023655977100133896, Loss G: 4.075460433959961\n",
      "Epoch: 35. Batches seen: 100.\n",
      "Loss D: 0.06675586104393005, Loss G: 4.464229583740234\n",
      "Epoch: 36. Batches seen: 0.\n",
      "Loss D: 0.035043224692344666, Loss G: 3.2468600273132324\n",
      "Epoch: 36. Batches seen: 50.\n",
      "Loss D: 0.09534740447998047, Loss G: 2.100497245788574\n",
      "Epoch: 36. Batches seen: 100.\n",
      "Loss D: 0.07085223495960236, Loss G: 2.2452523708343506\n",
      "Epoch: 37. Batches seen: 0.\n",
      "Loss D: 0.11963431537151337, Loss G: 3.65348482131958\n",
      "Epoch: 37. Batches seen: 50.\n",
      "Loss D: 0.05739501118659973, Loss G: 2.6399149894714355\n",
      "Epoch: 37. Batches seen: 100.\n",
      "Loss D: 0.04007776081562042, Loss G: 3.6983749866485596\n",
      "Epoch: 38. Batches seen: 0.\n",
      "Loss D: 0.576532781124115, Loss G: 2.311875820159912\n",
      "Epoch: 38. Batches seen: 50.\n",
      "Loss D: 0.23422175645828247, Loss G: 2.4442877769470215\n",
      "Epoch: 38. Batches seen: 100.\n",
      "Loss D: 0.39982298016548157, Loss G: 2.8294382095336914\n",
      "Epoch: 39. Batches seen: 0.\n",
      "Loss D: 0.10411585122346878, Loss G: 2.342804193496704\n",
      "Epoch: 39. Batches seen: 50.\n",
      "Loss D: 0.19183245301246643, Loss G: 1.782403826713562\n",
      "Epoch: 39. Batches seen: 100.\n",
      "Loss D: 0.15197472274303436, Loss G: 2.2219550609588623\n",
      "Epoch: 40. Batches seen: 0.\n",
      "Loss D: 0.3921142816543579, Loss G: 1.9800012111663818\n",
      "Epoch: 40. Batches seen: 50.\n",
      "Loss D: 0.3246568441390991, Loss G: 2.2285380363464355\n",
      "Epoch: 40. Batches seen: 100.\n",
      "Loss D: 0.03857865929603577, Loss G: 3.5708329677581787\n",
      "Epoch: 41. Batches seen: 0.\n",
      "Loss D: 1.1027905941009521, Loss G: 1.0608985424041748\n",
      "Epoch: 41. Batches seen: 50.\n",
      "Loss D: 0.4828464090824127, Loss G: 1.323203206062317\n",
      "Epoch: 41. Batches seen: 100.\n",
      "Loss D: 0.7025893330574036, Loss G: 2.30354642868042\n",
      "Epoch: 42. Batches seen: 0.\n",
      "Loss D: 0.42846396565437317, Loss G: 3.0278403759002686\n",
      "Epoch: 42. Batches seen: 50.\n",
      "Loss D: 0.23451107740402222, Loss G: 2.2641749382019043\n",
      "Epoch: 42. Batches seen: 100.\n",
      "Loss D: 0.06400032341480255, Loss G: 2.962301015853882\n",
      "Epoch: 43. Batches seen: 0.\n",
      "Loss D: 0.18232297897338867, Loss G: 1.9923150539398193\n",
      "Epoch: 43. Batches seen: 50.\n",
      "Loss D: 0.20231735706329346, Loss G: 2.15472412109375\n",
      "Epoch: 43. Batches seen: 100.\n",
      "Loss D: 0.377376526594162, Loss G: 3.3226494789123535\n",
      "Epoch: 44. Batches seen: 0.\n",
      "Loss D: 0.7362736463546753, Loss G: 1.8697221279144287\n",
      "Epoch: 44. Batches seen: 50.\n",
      "Loss D: 0.39177054166793823, Loss G: 2.157686471939087\n",
      "Epoch: 44. Batches seen: 100.\n",
      "Loss D: 0.1172202005982399, Loss G: 2.2685985565185547\n",
      "Epoch: 45. Batches seen: 0.\n",
      "Loss D: 0.10196604579687119, Loss G: 2.520540952682495\n",
      "Epoch: 45. Batches seen: 50.\n",
      "Loss D: 0.2783902883529663, Loss G: 1.8745455741882324\n",
      "Epoch: 45. Batches seen: 100.\n",
      "Loss D: 0.14371061325073242, Loss G: 3.8809022903442383\n",
      "Epoch: 46. Batches seen: 0.\n",
      "Loss D: 1.0417723655700684, Loss G: 1.6107780933380127\n",
      "Epoch: 46. Batches seen: 50.\n",
      "Loss D: 0.1091250404715538, Loss G: 3.906620740890503\n",
      "Epoch: 46. Batches seen: 100.\n",
      "Loss D: 0.34757718443870544, Loss G: 3.298919439315796\n",
      "Epoch: 47. Batches seen: 0.\n",
      "Loss D: 0.0963735580444336, Loss G: 2.518122673034668\n",
      "Epoch: 47. Batches seen: 50.\n",
      "Loss D: 0.13277465105056763, Loss G: 2.6298210620880127\n",
      "Epoch: 47. Batches seen: 100.\n",
      "Loss D: 0.8666196465492249, Loss G: 3.1004018783569336\n",
      "Epoch: 48. Batches seen: 0.\n",
      "Loss D: 0.2949135899543762, Loss G: 3.944157600402832\n",
      "Epoch: 48. Batches seen: 50.\n",
      "Loss D: 0.0902850553393364, Loss G: 2.66701340675354\n",
      "Epoch: 48. Batches seen: 100.\n",
      "Loss D: 0.15719930827617645, Loss G: 3.413882255554199\n",
      "Epoch: 49. Batches seen: 0.\n",
      "Loss D: 0.4116559624671936, Loss G: 1.583844780921936\n",
      "Epoch: 49. Batches seen: 50.\n",
      "Loss D: 0.21607135236263275, Loss G: 2.9200892448425293\n",
      "Epoch: 49. Batches seen: 100.\n",
      "Loss D: 0.1351790577173233, Loss G: 3.0959410667419434\n",
      "Epoch: 50. Batches seen: 0.\n",
      "Loss D: 0.3955245316028595, Loss G: 4.3108439445495605\n",
      "Epoch: 50. Batches seen: 50.\n",
      "Loss D: 0.3550206422805786, Loss G: 1.7668298482894897\n",
      "Epoch: 50. Batches seen: 100.\n",
      "Loss D: 0.09120002388954163, Loss G: 3.169239044189453\n",
      "Epoch: 51. Batches seen: 0.\n",
      "Loss D: 0.2650328278541565, Loss G: 2.732165813446045\n",
      "Epoch: 51. Batches seen: 50.\n",
      "Loss D: 0.20407673716545105, Loss G: 3.2205982208251953\n",
      "Epoch: 51. Batches seen: 100.\n",
      "Loss D: 0.045871175825595856, Loss G: 3.047006130218506\n",
      "Epoch: 52. Batches seen: 0.\n",
      "Loss D: 0.13475647568702698, Loss G: 2.767798900604248\n",
      "Epoch: 52. Batches seen: 50.\n",
      "Loss D: 0.6074231863021851, Loss G: 1.1139031648635864\n",
      "Epoch: 52. Batches seen: 100.\n",
      "Loss D: 0.27167266607284546, Loss G: 1.7160663604736328\n",
      "Epoch: 53. Batches seen: 0.\n",
      "Loss D: 0.3803076148033142, Loss G: 2.464888095855713\n",
      "Epoch: 53. Batches seen: 50.\n",
      "Loss D: 0.5584959983825684, Loss G: 1.5534908771514893\n",
      "Epoch: 53. Batches seen: 100.\n",
      "Loss D: 0.2252238541841507, Loss G: 3.4666261672973633\n",
      "Epoch: 54. Batches seen: 0.\n",
      "Loss D: 0.3529667258262634, Loss G: 2.1630585193634033\n",
      "Epoch: 54. Batches seen: 50.\n",
      "Loss D: 0.40520691871643066, Loss G: 3.4411869049072266\n",
      "Epoch: 54. Batches seen: 100.\n",
      "Loss D: 0.06898380070924759, Loss G: 3.895153045654297\n",
      "Epoch: 55. Batches seen: 0.\n",
      "Loss D: 0.18946807086467743, Loss G: 2.0133209228515625\n",
      "Epoch: 55. Batches seen: 50.\n",
      "Loss D: 0.4391080141067505, Loss G: 2.5218324661254883\n",
      "Epoch: 55. Batches seen: 100.\n",
      "Loss D: 0.8985493183135986, Loss G: 1.5246864557266235\n",
      "Epoch: 56. Batches seen: 0.\n",
      "Loss D: 0.11682774126529694, Loss G: 2.673111915588379\n",
      "Epoch: 56. Batches seen: 50.\n",
      "Loss D: 0.873726487159729, Loss G: 1.3680024147033691\n",
      "Epoch: 56. Batches seen: 100.\n",
      "Loss D: 0.3466915786266327, Loss G: 1.2629531621932983\n",
      "Epoch: 57. Batches seen: 0.\n",
      "Loss D: 0.16933467984199524, Loss G: 3.5354843139648438\n",
      "Epoch: 57. Batches seen: 50.\n",
      "Loss D: 0.137985497713089, Loss G: 2.7902355194091797\n",
      "Epoch: 57. Batches seen: 100.\n",
      "Loss D: 0.11790738254785538, Loss G: 2.332461357116699\n",
      "Epoch: 58. Batches seen: 0.\n",
      "Loss D: 0.4695720374584198, Loss G: 1.578292727470398\n",
      "Epoch: 58. Batches seen: 50.\n",
      "Loss D: 0.14176589250564575, Loss G: 4.366591453552246\n",
      "Epoch: 58. Batches seen: 100.\n",
      "Loss D: 0.2872723340988159, Loss G: 2.330904960632324\n",
      "Epoch: 59. Batches seen: 0.\n",
      "Loss D: 0.13721072673797607, Loss G: 2.4836812019348145\n",
      "Epoch: 59. Batches seen: 50.\n",
      "Loss D: 0.2750759720802307, Loss G: 2.4385337829589844\n",
      "Epoch: 59. Batches seen: 100.\n",
      "Loss D: 0.09312868863344193, Loss G: 2.7920241355895996\n",
      "Epoch: 60. Batches seen: 0.\n",
      "Loss D: 0.9027212262153625, Loss G: 1.9073455333709717\n",
      "Epoch: 60. Batches seen: 50.\n",
      "Loss D: 0.35801297426223755, Loss G: 2.4877824783325195\n",
      "Epoch: 60. Batches seen: 100.\n",
      "Loss D: 0.9623979330062866, Loss G: 1.096007227897644\n",
      "Epoch: 61. Batches seen: 0.\n",
      "Loss D: 0.2091466188430786, Loss G: 3.0216331481933594\n",
      "Epoch: 61. Batches seen: 50.\n",
      "Loss D: 0.7127758264541626, Loss G: 1.6455764770507812\n",
      "Epoch: 61. Batches seen: 100.\n",
      "Loss D: 0.2407235950231552, Loss G: 2.054399013519287\n",
      "Epoch: 62. Batches seen: 0.\n",
      "Loss D: 0.11095388978719711, Loss G: 4.839555740356445\n",
      "Epoch: 62. Batches seen: 50.\n",
      "Loss D: 0.42904290556907654, Loss G: 1.664980173110962\n",
      "Epoch: 62. Batches seen: 100.\n",
      "Loss D: 0.13514310121536255, Loss G: 2.7146434783935547\n",
      "Epoch: 63. Batches seen: 0.\n",
      "Loss D: 0.015664048492908478, Loss G: 7.359287738800049\n",
      "Epoch: 63. Batches seen: 50.\n",
      "Loss D: 0.10760942101478577, Loss G: 3.1012282371520996\n",
      "Epoch: 63. Batches seen: 100.\n",
      "Loss D: 0.349669873714447, Loss G: 1.64556086063385\n",
      "Epoch: 64. Batches seen: 0.\n",
      "Loss D: 0.0369500070810318, Loss G: 4.530998706817627\n",
      "Epoch: 64. Batches seen: 50.\n",
      "Loss D: 0.10214638710021973, Loss G: 5.667649269104004\n",
      "Epoch: 64. Batches seen: 100.\n",
      "Loss D: 0.06924109160900116, Loss G: 2.9154975414276123\n",
      "Epoch: 65. Batches seen: 0.\n",
      "Loss D: 0.06314851343631744, Loss G: 3.492415428161621\n",
      "Epoch: 65. Batches seen: 50.\n",
      "Loss D: 0.08705585449934006, Loss G: 3.626979112625122\n",
      "Epoch: 65. Batches seen: 100.\n",
      "Loss D: 0.12907461822032928, Loss G: 2.232067584991455\n",
      "Epoch: 66. Batches seen: 0.\n",
      "Loss D: 0.16635091602802277, Loss G: 4.81505012512207\n",
      "Epoch: 66. Batches seen: 50.\n",
      "Loss D: 0.1646527498960495, Loss G: 2.5001540184020996\n",
      "Epoch: 66. Batches seen: 100.\n",
      "Loss D: 0.03508061543107033, Loss G: 4.789911270141602\n",
      "Epoch: 67. Batches seen: 0.\n",
      "Loss D: 0.03990411385893822, Loss G: 3.167637825012207\n",
      "Epoch: 67. Batches seen: 50.\n",
      "Loss D: 0.14722409844398499, Loss G: 2.7449936866760254\n",
      "Epoch: 67. Batches seen: 100.\n",
      "Loss D: 0.270375519990921, Loss G: 3.6473124027252197\n",
      "Epoch: 68. Batches seen: 0.\n",
      "Loss D: 0.36387866735458374, Loss G: 1.852613925933838\n",
      "Epoch: 68. Batches seen: 50.\n",
      "Loss D: 0.08563880622386932, Loss G: 3.1589245796203613\n",
      "Epoch: 68. Batches seen: 100.\n",
      "Loss D: 0.1379043310880661, Loss G: 4.39785099029541\n",
      "Epoch: 69. Batches seen: 0.\n",
      "Loss D: 0.4622606039047241, Loss G: 1.4474188089370728\n",
      "Epoch: 69. Batches seen: 50.\n",
      "Loss D: 0.13644789159297943, Loss G: 2.304271697998047\n",
      "Epoch: 69. Batches seen: 100.\n",
      "Loss D: 0.5900670289993286, Loss G: 3.7290821075439453\n",
      "Epoch: 70. Batches seen: 0.\n",
      "Loss D: 0.10614985972642899, Loss G: 2.1527295112609863\n",
      "Epoch: 70. Batches seen: 50.\n",
      "Loss D: 0.18686455488204956, Loss G: 2.251951217651367\n",
      "Epoch: 70. Batches seen: 100.\n",
      "Loss D: 0.55720454454422, Loss G: 2.6973161697387695\n",
      "Epoch: 71. Batches seen: 0.\n",
      "Loss D: 0.014697516337037086, Loss G: 4.593603134155273\n",
      "Epoch: 71. Batches seen: 50.\n",
      "Loss D: 0.28083333373069763, Loss G: 2.1252167224884033\n",
      "Epoch: 71. Batches seen: 100.\n",
      "Loss D: 1.0149322748184204, Loss G: 1.5987370014190674\n",
      "Epoch: 72. Batches seen: 0.\n",
      "Loss D: 0.9804311990737915, Loss G: 1.21918785572052\n",
      "Epoch: 72. Batches seen: 50.\n",
      "Loss D: 0.09595745801925659, Loss G: 3.789564609527588\n",
      "Epoch: 72. Batches seen: 100.\n",
      "Loss D: 0.0865132212638855, Loss G: 3.735168933868408\n",
      "Epoch: 73. Batches seen: 0.\n",
      "Loss D: 0.09339669346809387, Loss G: 2.421067237854004\n",
      "Epoch: 73. Batches seen: 50.\n",
      "Loss D: 0.10844602435827255, Loss G: 4.805182456970215\n",
      "Epoch: 73. Batches seen: 100.\n",
      "Loss D: 0.12005738914012909, Loss G: 2.5739846229553223\n",
      "Epoch: 74. Batches seen: 0.\n",
      "Loss D: 0.02697320468723774, Loss G: 3.6980438232421875\n",
      "Epoch: 74. Batches seen: 50.\n",
      "Loss D: 0.2032875120639801, Loss G: 2.8062305450439453\n",
      "Epoch: 74. Batches seen: 100.\n",
      "Loss D: 0.12249385565519333, Loss G: 4.23298454284668\n",
      "Epoch: 75. Batches seen: 0.\n",
      "Loss D: 0.08794985711574554, Loss G: 3.680807590484619\n",
      "Epoch: 75. Batches seen: 50.\n",
      "Loss D: 0.27706170082092285, Loss G: 1.8974560499191284\n",
      "Epoch: 75. Batches seen: 100.\n",
      "Loss D: 0.10885991901159286, Loss G: 3.864267349243164\n",
      "Epoch: 76. Batches seen: 0.\n",
      "Loss D: 0.006621649954468012, Loss G: 6.385573387145996\n",
      "Epoch: 76. Batches seen: 50.\n",
      "Loss D: 0.05347689986228943, Loss G: 3.272749185562134\n",
      "Epoch: 76. Batches seen: 100.\n",
      "Loss D: 0.022096209228038788, Loss G: 3.8782787322998047\n",
      "Epoch: 77. Batches seen: 0.\n",
      "Loss D: 0.23421326279640198, Loss G: 2.838345527648926\n",
      "Epoch: 77. Batches seen: 50.\n",
      "Loss D: 0.056823067367076874, Loss G: 3.2346346378326416\n",
      "Epoch: 77. Batches seen: 100.\n",
      "Loss D: 0.09856032580137253, Loss G: 2.293877124786377\n",
      "Epoch: 78. Batches seen: 0.\n",
      "Loss D: 0.23680011928081512, Loss G: 5.65566349029541\n",
      "Epoch: 78. Batches seen: 50.\n",
      "Loss D: 0.0237283855676651, Loss G: 4.164737224578857\n",
      "Epoch: 78. Batches seen: 100.\n",
      "Loss D: 0.10878992825746536, Loss G: 5.002745628356934\n",
      "Epoch: 79. Batches seen: 0.\n",
      "Loss D: 0.4774385988712311, Loss G: 1.553147315979004\n",
      "Epoch: 79. Batches seen: 50.\n",
      "Loss D: 0.32955074310302734, Loss G: 2.039475917816162\n",
      "Epoch: 79. Batches seen: 100.\n",
      "Loss D: 0.15748104453086853, Loss G: 2.9834353923797607\n"
     ]
    }
   ],
   "source": [
    "fake_images = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_index, (real_images, labels) in enumerate(tumor_dataloader):\n",
    "        real_images = real_images.to(device)\n",
    "        noise = torch.randn(batch_size, z_dim, 1, 1).to(device) # For DCGAN (batch_size, z_dim, 1, 1), for regular GAN (batch_size, z_dim)\n",
    "        fake = gen(noise)\n",
    "        \n",
    "        # Train the discriminator max log(D(X)) + log(1 - (D(G(X))))\n",
    "        disc_real = disc(real_images).reshape(-1) # Flatten the output\n",
    "        loss_disc_real = loss_function(disc_real, torch.ones_like(disc_real))\n",
    "\n",
    "        disc_fake = disc(fake.detach()).reshape(-1)\n",
    "        loss_disc_fake = loss_function(disc_fake, torch.zeros_like(disc_fake))\n",
    "        \n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        loss_disc.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Train the Generator max log(D(G(z)))\n",
    "        output = disc(fake).reshape(-1)\n",
    "        loss_gen = loss_function(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_index % 50 == 0:\n",
    "            print(f'Epoch: {epoch}. Batches seen: {batch_index}.')\n",
    "            fake_images.append(fake)\n",
    "            print(f'Loss D: {loss_disc.item()}, Loss G: {loss_gen.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e6a787d-eeb3-4085-b669-a744ecff7919",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fake_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mfake_images\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fake_images' is not defined"
     ]
    }
   ],
   "source": [
    "len(fake_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2795b4d7-408c-40e5-9347-f2e36538bb03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fake_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fake_image \u001b[38;5;241m=\u001b[39m \u001b[43mfake_images\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(fake_image[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Visualize the image\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fake_images' is not defined"
     ]
    }
   ],
   "source": [
    "fake_image = fake_images[-1]\n",
    "print(fake_image[0].shape)\n",
    "\n",
    "# Visualize the image\n",
    "visualize_image(fake_image[0].cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c754a1be-efa1-4673-8fed-5d9b4768b6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake Generated Images:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fake_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m grid \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m, i)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m visualize_image(\u001b[43mfake_image\u001b[49m[i]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fake_image' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH8AAABkCAYAAACvrO9LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAA/0lEQVR4nO3RQREAIAzAMMC/5yFjjyYKetc7M3NIetsB7DE/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPww88PMDzM/zPywD89YBMSAdNZgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Fake Generated Images:')\n",
    "\n",
    "for i in range(1, 17):\n",
    "    grid = plt.subplot(4, 4, i)\n",
    "    plt.axis(False)\n",
    "    visualize_image(fake_image[i].cpu().detach())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c18b27ba-8a4f-4ff3-a140-ff2685aacb23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Saving the DCGAN\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mgen\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved models/Generator.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(disc\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved models/Discriminator.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gen' is not defined"
     ]
    }
   ],
   "source": [
    "# Saving the DCGAN\n",
    "torch.save(gen.state_dict(), 'saved models/Generator.pth')\n",
    "torch.save(disc.state_dict(), 'saved models/Discriminator.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74a5e11-086f-47e4-a17a-eb206a21a8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
