{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2c6d3b-2600-4c76-9bca-7a2226200f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import Dataset # Base dataset class\n",
    "from torch.utils.data import DataLoader # For batching and shuffling data\n",
    "\n",
    "from torchvision import datasets # For built-in datasets\n",
    "from torchvision import transforms # For transforming data from one format to another\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773adaa4-f3e6-4bc3-8432-39c7b74dc09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu118'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d5cdcb-a31b-4b8a-8275-081256dbb7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc21c91-fcab-4db8-a7f4-f6f914a109bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the MNIST handwritten digits dataset\n",
    "# Get the training dataset\n",
    "MNIST_DIGITS_TRAIN = datasets.MNIST(root='./datasets/', \n",
    "                              train=True, download=True, \n",
    "                              transform=transforms.ToTensor())\n",
    "# Get the testing dataset\n",
    "MNIST_DIGITS_TEST = datasets.MNIST(root='./datasets/', \n",
    "                              train=False, download=True, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "len(MNIST_DIGITS_TRAIN), len(MNIST_DIGITS_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11aaaa03-37c2-4364-b43e-5397a7990d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = MNIST_DIGITS_TRAIN.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e348ae-c7e4-479a-aa23-6b68d887074c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize our data\n",
    "sample_X, sample_label = MNIST_DIGITS_TRAIN[0]\n",
    "sample_X, sample_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1efe50f8-b6b9-411c-906f-cafbf8a2822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_X.shape # (C, H, W) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "322d6f2e-8553-4074-aaf1-ab4fb8cd437d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_X = sample_X.squeeze(dim=0) # Get rid of the outer dimension\n",
    "sample_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b36c9be7-d0af-4baf-bcad-e739215100e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label: 5 - five')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the image data using matplotlib\n",
    "plt.imshow(sample_X, cmap='gray')\n",
    "plt.axis(False)\n",
    "plt.title(f'Label: {LABELS[sample_label]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fd3bf2e-6321-49b3-ba38-0f9979e4c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to plot random images\n",
    "def plot_sample(index):\n",
    "    # Get the image onto the correct format\n",
    "    sample_X, sample_label = MNIST_DIGITS_TRAIN[index]\n",
    "    sample_X = sample_X.squeeze(dim=0)\n",
    "\n",
    "    # Show the image\n",
    "    plt.imshow(sample_X, cmap='gray')\n",
    "    plt.axis(False)\n",
    "    plt.title(f'Label: {LABELS[sample_label]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb14630d-bcb7-4a12-a1f4-f476e6445cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(5) # Plot the 6th image in our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33b04a1a-eef3-4f96-b7cf-abc258c7fb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "636359ba-f6ea-4619-95af-ced176cfa326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training batches of size 32: 1875\n",
      "No. of testing batches of size 32: 313\n"
     ]
    }
   ],
   "source": [
    "# Turn the image data into batches\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(dataset=MNIST_DIGITS_TRAIN, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=MNIST_DIGITS_TEST, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'No. of training batches of size {batch_size}: {len(train_dataloader)}')\n",
    "print(f'No. of testing batches of size {batch_size}: {len(test_dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6c8da1e-6850-4e2e-9b91-2fb4a042eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CNN Model\n",
    "class MNISTDigitClassifier(nn.Module):\n",
    "    def __init__(self, in_features, hidden_units, out_features):\n",
    "        super().__init__()\n",
    "        self.conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_features, out_channels=hidden_units, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "        self.conv_layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(), # (B, C, H, W) -> (B, C*H*W)\n",
    "            nn.Linear(in_features=360, out_features=len(LABELS)) # The value 360 is found by the computations\n",
    "            # done in the cells below.\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        conv1_output = self.conv_layer_1(X)\n",
    "        conv2_output = self.conv_layer_2(conv1_output)\n",
    "        classifier_output = self.classifier(conv2_output)\n",
    "        \n",
    "        return classifier_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c701e1ed-fe0a-4074-ba54-45a585c034e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the original image: torch.Size([1, 1, 28, 28])\n",
      "Shape after first conv. layer: torch.Size([1, 10, 13, 13])\n",
      "Shape after second conv. layer: torch.Size([1, 10, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "# First, we will send a single image through our convolutional layers to see the transformed output shape of our image\n",
    "# after going through the two convolutional layers\n",
    "\n",
    "single_image, single_image_label =  MNIST_DIGITS_TRAIN[0]# (C, H, W)\n",
    "single_image = single_image.unsqueeze(dim=0) # (B, C, H, W)\n",
    "\n",
    "# Just the convolution layers\n",
    "conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "conv_layer_2 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=10, out_channels=len(LABELS), kernel_size=(2, 2), stride=1, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2, 2))\n",
    ")\n",
    "\n",
    "\n",
    "# Pass it through the model\n",
    "output1 = conv_layer_1(single_image)\n",
    "output2 = conv_layer_2(output1)\n",
    "print(f'Shape of the original image: {single_image.shape}')\n",
    "print(f'Shape after first conv. layer: {output1.shape}')\n",
    "print(f'Shape after second conv. layer: {output2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c113ccc-faf9-4e81-8213-8ef35863faa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, we can see that the original image (1, 1, 28, 28) gets transformed into a shape of (1, 10, 6, 6). \n",
    "# After flattening the image, we will end up with a shape of (1, 360).\n",
    "# Therefore, the in_features for the linear layer should be 360.\n",
    "# We will update this in the model above.\n",
    "cnn_model = MNISTDigitClassifier(in_features=1, hidden_units=10, out_features=len(LABELS))\n",
    "logits = cnn_model(single_image)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2853150f-9943-4cc3-85d7-5b0a71b7b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the loss function and the optimizer\n",
    "learning_rate = 0.01\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(cnn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a74694af-3473-4918-9547-2b40d9ccbe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and testing loops\n",
    "def train_step(model, X, y): # X -> batch of images, y -> vector of labels\n",
    "    # Put the model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = model(X) \n",
    "\n",
    "    # Calculate the loss\n",
    "    # The loss function expects the shape of the logits to be in [batch_size, no. of classes] and the shape of the truth labels to be in \n",
    "    # [batch_size, ]\n",
    "    loss = loss_function(logits, y)\n",
    "\n",
    "    # Clear the gradients stored in the model parameters from previous backpropagation\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backpropagate (Calculate gradients)\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the model parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    return {'loss': loss.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55cf65d8-012e-4d0b-8137-9cd989bb4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, X, y):\n",
    "    # Put the model in testing mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        logits = model(X)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_function(logits, y)\n",
    "        \n",
    "        predicted_labels = logits.argmax(dim=1)\n",
    "\n",
    "        # Calculate the current batch's accuracy\n",
    "        total_accurate = (predicted_labels == y).sum().item()\n",
    "        accuracy_percentage = (float(total_accurate) / len(y)) * 100\n",
    "\n",
    "    return {'loss': loss.item(), 'accuracy': accuracy_percentage}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a17adbba-3a35-47ef-b639-8acd3d2d380e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "cnn_model = cnn_model.to(device)\n",
    "next(cnn_model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccae2ae4-c5ef-4399-b84f-ac7990b371d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.283294439315796\n"
     ]
    }
   ],
   "source": [
    "# Run through a single train and test step\n",
    "train_dict = train_step(cnn_model, single_image.to(device), torch.tensor(single_image_label).unsqueeze(dim=0).to(device))\n",
    "print(train_dict['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76eb3604-0e0e-4475-a2e1-748fd899f502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- EPOCH: 1. ----------\n",
      "Batch: 200. Training Loss: 2.0840911865234375\n",
      "Average test loss: 2.1035626700130132. Average test accuracy: 49.171325878594246%\n",
      "Batch: 400. Training Loss: 0.7681263089179993\n",
      "Average test loss: 0.7200004486039805. Average test accuracy: 79.28314696485623%\n",
      "Batch: 600. Training Loss: 0.3066518306732178\n",
      "Average test loss: 0.5417288582022197. Average test accuracy: 83.11701277955271%\n",
      "Batch: 800. Training Loss: 0.4912102520465851\n",
      "Average test loss: 0.47706651844726966. Average test accuracy: 85.1238019169329%\n",
      "Batch: 1000. Training Loss: 0.23039640486240387\n",
      "Average test loss: 0.43743037744261587. Average test accuracy: 86.42172523961662%\n",
      "Batch: 1200. Training Loss: 0.4992910623550415\n",
      "Average test loss: 0.4286290103206619. Average test accuracy: 86.66134185303514%\n",
      "Batch: 1400. Training Loss: 0.470729798078537\n",
      "Average test loss: 0.38511359096525577. Average test accuracy: 88.39856230031948%\n",
      "Batch: 1600. Training Loss: 0.34692806005477905\n",
      "Average test loss: 0.3758327936093076. Average test accuracy: 88.67811501597444%\n",
      "Batch: 1800. Training Loss: 0.7205681204795837\n",
      "Average test loss: 0.3605370324985764. Average test accuracy: 88.87779552715655%\n",
      "---------- EPOCH: 2. ----------\n",
      "Batch: 200. Training Loss: 0.3248065114021301\n",
      "Average test loss: 0.3592052742505607. Average test accuracy: 88.99760383386581%\n",
      "Batch: 400. Training Loss: 0.5159369707107544\n",
      "Average test loss: 0.3354275013965825. Average test accuracy: 90.05591054313099%\n",
      "Batch: 600. Training Loss: 0.16717848181724548\n",
      "Average test loss: 0.3191498116956066. Average test accuracy: 90.51517571884985%\n",
      "Batch: 800. Training Loss: 0.4855785369873047\n",
      "Average test loss: 0.3103918556135874. Average test accuracy: 91.12420127795527%\n",
      "Batch: 1000. Training Loss: 0.24929586052894592\n",
      "Average test loss: 0.28963093228709585. Average test accuracy: 91.80311501597444%\n",
      "Batch: 1200. Training Loss: 0.4141464829444885\n",
      "Average test loss: 0.29487395042571396. Average test accuracy: 91.34384984025559%\n",
      "Batch: 1400. Training Loss: 0.14179585874080658\n",
      "Average test loss: 0.2838875688433933. Average test accuracy: 91.75319488817891%\n",
      "Batch: 1600. Training Loss: 0.20381700992584229\n",
      "Average test loss: 0.29285944943515635. Average test accuracy: 91.32388178913737%\n",
      "Batch: 1800. Training Loss: 0.365612268447876\n",
      "Average test loss: 0.26139045040161846. Average test accuracy: 92.61182108626198%\n",
      "---------- EPOCH: 3. ----------\n",
      "Batch: 200. Training Loss: 0.39208900928497314\n",
      "Average test loss: 0.25928030092531024. Average test accuracy: 92.6417731629393%\n",
      "Batch: 400. Training Loss: 0.20760968327522278\n",
      "Average test loss: 0.25293973477753684. Average test accuracy: 92.92132587859425%\n",
      "Batch: 600. Training Loss: 0.19268666207790375\n",
      "Average test loss: 0.22812411097137217. Average test accuracy: 93.51038338658147%\n",
      "Batch: 800. Training Loss: 0.061855193227529526\n",
      "Average test loss: 0.22368902746980754. Average test accuracy: 93.78993610223642%\n",
      "Batch: 1000. Training Loss: 0.12194718420505524\n",
      "Average test loss: 0.21511572204268398. Average test accuracy: 93.85982428115015%\n",
      "Batch: 1200. Training Loss: 0.37851881980895996\n",
      "Average test loss: 0.20625062126475877. Average test accuracy: 94.00958466453675%\n",
      "Batch: 1400. Training Loss: 0.08117611706256866\n",
      "Average test loss: 0.19971442733483669. Average test accuracy: 94.34904153354633%\n",
      "Batch: 1600. Training Loss: 0.07846762984991074\n",
      "Average test loss: 0.20346038771150543. Average test accuracy: 94.06948881789137%\n",
      "Batch: 1800. Training Loss: 0.36813339591026306\n",
      "Average test loss: 0.1936185446154243. Average test accuracy: 94.3091054313099%\n",
      "---------- EPOCH: 4. ----------\n",
      "Batch: 200. Training Loss: 0.1848270148038864\n",
      "Average test loss: 0.18735281616366042. Average test accuracy: 94.4888178913738%\n",
      "Batch: 400. Training Loss: 0.09273136407136917\n",
      "Average test loss: 0.1802334997047203. Average test accuracy: 94.81829073482429%\n",
      "Batch: 600. Training Loss: 0.2809869647026062\n",
      "Average test loss: 0.17965304191572407. Average test accuracy: 94.64856230031948%\n",
      "Batch: 800. Training Loss: 0.14768023788928986\n",
      "Average test loss: 0.17353525409510676. Average test accuracy: 94.92811501597444%\n",
      "Batch: 1000. Training Loss: 0.15740454196929932\n",
      "Average test loss: 0.17046991846979426. Average test accuracy: 94.96805111821087%\n",
      "Batch: 1200. Training Loss: 0.15199153125286102\n",
      "Average test loss: 0.17676410869287607. Average test accuracy: 94.69848242811501%\n",
      "Batch: 1400. Training Loss: 0.10665356367826462\n",
      "Average test loss: 0.18241152490010135. Average test accuracy: 94.72843450479233%\n",
      "Batch: 1600. Training Loss: 0.041571810841560364\n",
      "Average test loss: 0.16196430812830837. Average test accuracy: 95.32747603833866%\n",
      "Batch: 1800. Training Loss: 0.24930478632450104\n",
      "Average test loss: 0.15774946429055578. Average test accuracy: 95.2276357827476%\n",
      "---------- EPOCH: 5. ----------\n",
      "Batch: 200. Training Loss: 0.0408681258559227\n",
      "Average test loss: 0.15510538799134782. Average test accuracy: 95.51717252396166%\n",
      "Batch: 400. Training Loss: 0.1824180632829666\n",
      "Average test loss: 0.1612369947093792. Average test accuracy: 95.17771565495208%\n",
      "Batch: 600. Training Loss: 0.12671639025211334\n",
      "Average test loss: 0.1444244442073206. Average test accuracy: 95.67691693290735%\n",
      "Batch: 800. Training Loss: 0.2495030164718628\n",
      "Average test loss: 0.14498865645462142. Average test accuracy: 95.78674121405751%\n",
      "Batch: 1000. Training Loss: 0.19311167299747467\n",
      "Average test loss: 0.14970785801182873. Average test accuracy: 95.51717252396166%\n",
      "Batch: 1200. Training Loss: 0.07015777379274368\n",
      "Average test loss: 0.14365768705319149. Average test accuracy: 95.62699680511182%\n",
      "Batch: 1400. Training Loss: 0.09342538565397263\n",
      "Average test loss: 0.14170152735866653. Average test accuracy: 95.56709265175719%\n",
      "Batch: 1600. Training Loss: 0.3541080355644226\n",
      "Average test loss: 0.1469310097963201. Average test accuracy: 95.43730031948881%\n",
      "Batch: 1800. Training Loss: 0.05940956994891167\n",
      "Average test loss: 0.14310859882246002. Average test accuracy: 95.46725239616613%\n",
      "---------- EPOCH: 6. ----------\n",
      "Batch: 200. Training Loss: 0.4147796630859375\n",
      "Average test loss: 0.13355865768683603. Average test accuracy: 95.96645367412141%\n",
      "Batch: 400. Training Loss: 0.20941200852394104\n",
      "Average test loss: 0.14610223448314605. Average test accuracy: 95.40734824281151%\n",
      "Batch: 600. Training Loss: 0.0640554279088974\n",
      "Average test loss: 0.12914870258498068. Average test accuracy: 95.86661341853035%\n",
      "Batch: 800. Training Loss: 0.08326997607946396\n",
      "Average test loss: 0.13472333041721948. Average test accuracy: 95.87659744408946%\n",
      "Batch: 1000. Training Loss: 0.16061286628246307\n",
      "Average test loss: 0.13914871729981784. Average test accuracy: 95.82667731629392%\n",
      "Batch: 1200. Training Loss: 0.035589125007390976\n",
      "Average test loss: 0.12982834576474378. Average test accuracy: 96.15615015974441%\n",
      "Batch: 1400. Training Loss: 0.14747494459152222\n",
      "Average test loss: 0.13149191861222395. Average test accuracy: 95.91653354632588%\n",
      "Batch: 1600. Training Loss: 0.11607107520103455\n",
      "Average test loss: 0.1305183051399494. Average test accuracy: 96.01637380191693%\n",
      "Batch: 1800. Training Loss: 0.15626224875450134\n",
      "Average test loss: 0.13095163818435393. Average test accuracy: 96.01637380191693%\n",
      "---------- EPOCH: 7. ----------\n",
      "Batch: 200. Training Loss: 0.1168808564543724\n",
      "Average test loss: 0.1304130820247282. Average test accuracy: 96.14616613418531%\n",
      "Batch: 400. Training Loss: 0.02474229410290718\n",
      "Average test loss: 0.12976212193519948. Average test accuracy: 96.01637380191693%\n",
      "Batch: 600. Training Loss: 0.06903942674398422\n",
      "Average test loss: 0.1232551274231275. Average test accuracy: 96.28594249201278%\n",
      "Batch: 800. Training Loss: 0.02077370136976242\n",
      "Average test loss: 0.11846740085061806. Average test accuracy: 96.29592651757189%\n",
      "Batch: 1000. Training Loss: 0.18115916848182678\n",
      "Average test loss: 0.13081487334488084. Average test accuracy: 96.01637380191693%\n",
      "Batch: 1200. Training Loss: 0.10941077768802643\n",
      "Average test loss: 0.1288260415229149. Average test accuracy: 95.9564696485623%\n",
      "Batch: 1400. Training Loss: 0.02166604809463024\n",
      "Average test loss: 0.12101101506904613. Average test accuracy: 96.24600638977635%\n",
      "Batch: 1600. Training Loss: 0.22362393140792847\n",
      "Average test loss: 0.12268800337980397. Average test accuracy: 96.27595846645367%\n",
      "Batch: 1800. Training Loss: 0.12877094745635986\n",
      "Average test loss: 0.11728741873290759. Average test accuracy: 96.18610223642173%\n",
      "---------- EPOCH: 8. ----------\n",
      "Batch: 200. Training Loss: 0.053146544843912125\n",
      "Average test loss: 0.1159875777210838. Average test accuracy: 96.5055910543131%\n",
      "Batch: 400. Training Loss: 0.13937070965766907\n",
      "Average test loss: 0.11163607694040507. Average test accuracy: 96.52555910543131%\n",
      "Batch: 600. Training Loss: 0.08383579552173615\n",
      "Average test loss: 0.11438013946997544. Average test accuracy: 96.38578274760384%\n",
      "Batch: 800. Training Loss: 0.15904946625232697\n",
      "Average test loss: 0.11327194153166081. Average test accuracy: 96.46565495207668%\n",
      "Batch: 1000. Training Loss: 0.07088026404380798\n",
      "Average test loss: 0.11872787817237013. Average test accuracy: 96.24600638977635%\n",
      "Batch: 1200. Training Loss: 0.024321870878338814\n",
      "Average test loss: 0.11141367765651576. Average test accuracy: 96.495607028754%\n",
      "Batch: 1400. Training Loss: 0.12636250257492065\n",
      "Average test loss: 0.11269104350045824. Average test accuracy: 96.55551118210863%\n",
      "Batch: 1600. Training Loss: 0.03563591465353966\n",
      "Average test loss: 0.10647800687820273. Average test accuracy: 96.44568690095846%\n",
      "Batch: 1800. Training Loss: 0.16878220438957214\n",
      "Average test loss: 0.11056829670097489. Average test accuracy: 96.37579872204473%\n",
      "---------- EPOCH: 9. ----------\n",
      "Batch: 200. Training Loss: 0.054911576211452484\n",
      "Average test loss: 0.10801000133254968. Average test accuracy: 96.47563897763578%\n",
      "Batch: 400. Training Loss: 0.0927470400929451\n",
      "Average test loss: 0.11050854141179758. Average test accuracy: 96.37579872204473%\n",
      "Batch: 600. Training Loss: 0.03916420787572861\n",
      "Average test loss: 0.10669838673358534. Average test accuracy: 96.61541533546325%\n",
      "Batch: 800. Training Loss: 0.1454572081565857\n",
      "Average test loss: 0.10682956393106659. Average test accuracy: 96.64536741214057%\n",
      "Batch: 1000. Training Loss: 0.09933310747146606\n",
      "Average test loss: 0.10436279907675323. Average test accuracy: 96.57547923322684%\n",
      "Batch: 1200. Training Loss: 0.13163650035858154\n",
      "Average test loss: 0.11573081210771867. Average test accuracy: 96.40575079872204%\n",
      "Batch: 1400. Training Loss: 0.0955604538321495\n",
      "Average test loss: 0.10368369651151993. Average test accuracy: 96.79512779552715%\n",
      "Batch: 1600. Training Loss: 0.07252059876918793\n",
      "Average test loss: 0.10377910908106298. Average test accuracy: 96.57547923322684%\n",
      "Batch: 1800. Training Loss: 0.13067948818206787\n",
      "Average test loss: 0.10270176925577414. Average test accuracy: 96.70527156549521%\n",
      "---------- EPOCH: 10. ----------\n",
      "Batch: 200. Training Loss: 0.12200932204723358\n",
      "Average test loss: 0.1016992733589918. Average test accuracy: 96.62539936102236%\n",
      "Batch: 400. Training Loss: 0.08299700170755386\n",
      "Average test loss: 0.10030287921096916. Average test accuracy: 96.90495207667732%\n",
      "Batch: 600. Training Loss: 0.01778418943285942\n",
      "Average test loss: 0.09850261695872689. Average test accuracy: 96.75519169329074%\n",
      "Batch: 800. Training Loss: 0.18031726777553558\n",
      "Average test loss: 0.10016646313655098. Average test accuracy: 96.64536741214057%\n",
      "Batch: 1000. Training Loss: 0.021541453897953033\n",
      "Average test loss: 0.09722600775244929. Average test accuracy: 96.85503194888179%\n",
      "Batch: 1200. Training Loss: 0.18721647560596466\n",
      "Average test loss: 0.10081742026743824. Average test accuracy: 96.80511182108626%\n",
      "Batch: 1400. Training Loss: 0.08111761510372162\n",
      "Average test loss: 0.10034654753676173. Average test accuracy: 96.81509584664536%\n",
      "Batch: 1600. Training Loss: 0.02519945055246353\n",
      "Average test loss: 0.10382174386121422. Average test accuracy: 96.57547923322684%\n",
      "Batch: 1800. Training Loss: 0.041278112679719925\n",
      "Average test loss: 0.10040693071588261. Average test accuracy: 96.80511182108626%\n"
     ]
    }
   ],
   "source": [
    "# Create the training and testing loop\n",
    "epochs = 10\n",
    "for i in range(0, epochs):\n",
    "    batch = 1\n",
    "    print(f'---------- EPOCH: {i + 1}. ----------')\n",
    "    for [X, y] in train_dataloader:\n",
    "        train_dict = train_step(cnn_model, X.to(device), y.to(device))\n",
    "        loss = train_dict['loss']\n",
    "        batch += 1\n",
    "\n",
    "        if batch%200 == 0:\n",
    "            print(f'Batch: {batch}. Training Loss: {loss}')\n",
    "\n",
    "            # Test the model\n",
    "            average_test_loss = 0\n",
    "            average_test_accuracy = 0\n",
    "            for [test_X, test_y] in test_dataloader:\n",
    "                test_dict = test_step(cnn_model, test_X.to(device), test_y.to(device))\n",
    "                \n",
    "                test_loss = test_dict['loss']\n",
    "                accuracy = test_dict['accuracy']\n",
    "\n",
    "                average_test_loss += test_loss\n",
    "                average_test_accuracy += accuracy\n",
    "                \n",
    "            average_test_loss = average_test_loss / len(test_dataloader)\n",
    "            average_test_accuracy = average_test_accuracy / len(test_dataloader)\n",
    "            \n",
    "            print(f'Average test loss: {average_test_loss}. Average test accuracy: {average_test_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d3dff10-5cd1-4e1e-8313-81ad28c2e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions using the model\n",
    "def predict(model, X, y):\n",
    "    logits = model(X)\n",
    "\n",
    "    prediction_class = logits.argmax(dim=1).unsqueeze(dim=1)\n",
    "\n",
    "    print(f'Actual Label: {y}. Prediceted Label: {prediction_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7d5c28c-bb6f-4217-93c1-1fd901ed7663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: 7. Prediceted Label: tensor([[7]], device='cuda:0')\n",
      "Actual Label: 2. Prediceted Label: tensor([[2]], device='cuda:0')\n",
      "Actual Label: 1. Prediceted Label: tensor([[1]], device='cuda:0')\n",
      "Actual Label: 0. Prediceted Label: tensor([[0]], device='cuda:0')\n",
      "Actual Label: 4. Prediceted Label: tensor([[4]], device='cuda:0')\n",
      "Actual Label: 1. Prediceted Label: tensor([[1]], device='cuda:0')\n",
      "Actual Label: 4. Prediceted Label: tensor([[4]], device='cuda:0')\n",
      "Actual Label: 9. Prediceted Label: tensor([[9]], device='cuda:0')\n",
      "Actual Label: 5. Prediceted Label: tensor([[5]], device='cuda:0')\n",
      "Actual Label: 9. Prediceted Label: tensor([[9]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    X, y = MNIST_DIGITS_TEST[i]\n",
    "\n",
    "    X = X.unsqueeze(dim=0)\n",
    "    predict(cnn_model, X.to(device), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0c59ddc-c000-4d91-9b90-c0c35be5aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model on our own data\n",
    "# I have created a 28x28 image on paint.net of a handwritten 5\n",
    "# First we load it \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74d74e3e-4be6-45ca-9dee-c1311cff6d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAABYlBMVEUAAAAFBQULCwsMDAweHh4jIyMZGRkRERENDQ0EBAQTExNvb2+urq6+vr7Kysrt7e3y8vLe3t7Pz8/IyMjS0tKqqqodHR0JCQmUlJT6+vr+/v78/PxkZGQSEhLQ0ND////7+/vs7Ozl5eXu7u7Z2dnb29vz8/Ph4eE6OjoHBwfDw8NBQUEfHx8aGhouLi4CAgKfn581NTV0dHT9/f1VVVVRUVH5+fl5eXk5OTn09PSampoBAQEqKiq5ubkoKCgkJCQiIiIVFRXm5ubp6enc3NylpaVISEgKCgq7u7s7Ozv39/e3t7fd3d3Y2NggICDj4+MvLy8XFxfV1dWbm5sICAh3d3ctLS0sLCzg4ODv7++pqanw8PArKysDAwPR0dHq6uomJiZYWFjk5OR9fX0GBgbGxsZzc3OxsbFJSUk3NzddXV2dnZ2RkZEODg4cHBxubm6wsLCvr6+hoaF+fn5OTk4bGxv2N9/fAAABQ0lEQVR4AWNggANGJmYWVjZ2DiZOuBCMwcXNw8vHLyAoJCwiKgYThNLiEpJSMCAtgyYpKyevoKikrKiiqqSmroEmqaklpaito6PLxaajp6OPJslgIKVmiC4G5xsZS5rAOegMUzNjc3QxON/CUsrKGs5DY9goStna2Ts4YoYAUKG9kxS/M7+ii6ubO5o2IJeVX15eHhQMah6eGF7R85KXd/b28DGTkvK1Qdfr5y+lHmCtHygTZGwcHIImq68RGgZ2bbiTfAR6yMPV6ttKRWKYC5O1jpKKDoBxGBhCYvxiETzZOKn4BAQ3McknORzmhhRuL6lUDoRkmoK8NH96hj0ra0JmFo+lvJcMUjjqukYbS0l58Ssq8qtJSsmbZSNpZGBw98yJUIAkEmMvF/NchKFglnVevmtBenphUXFJKUbgoakdQC4A82cv0dwIX6UAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=P size=28x28>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('./datasets/images/five.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b5a9dbb-47bc-4a9f-a2eb-9730f9fcdf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_tensor = transforms.ToTensor() # Convert the raw image to tensor of format (C, H, W)\n",
    "img_tensor = convert_tensor(img)\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a4327e9-e4df-4ba7-894e-30204e159188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor = img_tensor.unsqueeze(dim=0) # Add the batch dimension\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "555abd8d-4347-4e8e-b279-bed409d5f02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: 5. Prediceted Label: tensor([[5]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "predict(cnn_model, img_tensor.to(device), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1d44b-2416-401e-871b-28c20f1b13b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
